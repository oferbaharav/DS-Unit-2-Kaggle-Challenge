{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ofer Baharav Copy of assignment_kaggle_challenge_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oferbaharav/DS-Unit-2-Kaggle-Challenge/blob/master/module1/Ofer_Baharav_Copy_of_assignment_kaggle_challenge_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxwutuhkGGM5",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 2, Module 1*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Decision Trees\n",
        "\n",
        "## Assignment\n",
        "- [ ] [Sign up for a Kaggle account](https://www.kaggle.com/), if you don’t already have one. Go to our Kaggle InClass competition website. You will be given the URL in Slack. Go to the Rules page. Accept the rules of the competition.\n",
        "- [ ] Do train/validate/test split with the Tanzania Waterpumps data.\n",
        "- [ ] Begin with baselines for classification.\n",
        "- [ ] Select features. Use a scikit-learn pipeline to encode categoricals, impute missing values, and fit a decision tree classifier.\n",
        "- [ ] Get your validation accuracy score.\n",
        "- [ ] Get and plot your feature importances.\n",
        "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "### Reading\n",
        "\n",
        "- A Visual Introduction to Machine Learning\n",
        "  - [Part 1: A Decision Tree](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)\n",
        "  - [Part 2: Bias and Variance](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/)\n",
        "- [Decision Trees: Advantages & Disadvantages](https://christophm.github.io/interpretable-ml-book/tree.html#advantages-2)\n",
        "- [How a Russian mathematician constructed a decision tree — by hand — to solve a medical problem](http://fastml.com/how-a-russian-mathematician-constructed-a-decision-tree-by-hand-to-solve-a-medical-problem/)\n",
        "- [How decision trees work](https://brohrer.github.io/how_decision_trees_work.html)\n",
        "- [Let’s Write a Decision Tree Classifier from Scratch](https://www.youtube.com/watch?v=LDRbO9a6XPU) — _Don’t worry about understanding the code, just get introduced to the concepts. This 10 minute video has excellent diagrams and explanations._\n",
        "- [Random Forests for Complete Beginners: The definitive guide to Random Forests and Decision Trees](https://victorzhou.com/blog/intro-to-random-forests/)\n",
        "\n",
        "\n",
        "### Doing\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Define a function to wrangle train, validate, and test sets in the same way. Clean outliers and engineer features. (For example, [what columns have zeros and shouldn't?](https://github.com/Quartz/bad-data-guide#zeros-replace-missing-values) What columns are duplicates, or nearly duplicates? Can you extract the year from date_recorded? Can you engineer new features, such as the number of years from waterpump construction to waterpump inspection?)\n",
        "- [ ] Try other [scikit-learn imputers](https://scikit-learn.org/stable/modules/impute.html).\n",
        "- [ ] Make exploratory visualizations and share on Slack.\n",
        "\n",
        "\n",
        "#### Exploratory visualizations\n",
        "\n",
        "Visualize the relationships between feature(s) and target. I recommend you do this with your training set, after splitting your data. \n",
        "\n",
        "For this problem, you may want to create a new column to represent the target as a number, 0 or 1. For example:\n",
        "\n",
        "```python\n",
        "train['functional'] = (train['status_group']=='functional').astype(int)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "You can try [Seaborn \"Categorical estimate\" plots](https://seaborn.pydata.org/tutorial/categorical.html) for features with reasonably few unique values. (With too many unique values, the plot is unreadable.)\n",
        "\n",
        "- Categorical features. (If there are too many unique values, you can replace less frequent values with \"OTHER.\")\n",
        "- Numeric features. (If there are too many unique values, you can [bin with pandas cut / qcut functions](https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html?highlight=qcut#discretization-and-quantiling).)\n",
        "\n",
        "You can try [Seaborn linear model plots](https://seaborn.pydata.org/tutorial/regression.html) with numeric features. For this classification problem, you may want to use the parameter `logistic=True`, but it can be slow.\n",
        "\n",
        "You do _not_ need to use Seaborn, but it's nice because it includes confidence intervals to visualize uncertainty.\n",
        "\n",
        "#### High-cardinality categoricals\n",
        "\n",
        "This code from a previous assignment demonstrates how to replace less frequent values with 'OTHER'\n",
        "\n",
        "```python\n",
        "# Reduce cardinality for NEIGHBORHOOD feature ...\n",
        "\n",
        "# Get a list of the top 10 neighborhoods\n",
        "top10 = train['NEIGHBORHOOD'].value_counts()[:10].index\n",
        "\n",
        "# At locations where the neighborhood is NOT in the top 10,\n",
        "# replace the neighborhood with 'OTHER'\n",
        "train.loc[~train['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'\n",
        "test.loc[~test['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "7ebe0e64-4181-4ccf-bb48-443888603481"
      },
      "source": [
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders==2.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 71kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 81kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 92kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.25.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.21.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (1.17.4)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (0.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders==2.*) (1.12.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QJBD4ruICm1m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e071e84-ddc6-4229-aa48-74d3d14fe0b3"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
        "#split train into train & val\n",
        "train, val = train_test_split(train, train_size=0.8, test_size=0.2,\n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "train.shape, val.shape, test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47520, 41), (11880, 41), (14358, 40))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Amxyx3xphbb",
        "colab": {}
      },
      "source": [
        "#Wrangle data\n",
        "import numpy as np\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    cols_with_zeros = ['longitude', 'latitude']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "            \n",
        "    # quantity & quantity_group are duplicates, so drop one\n",
        "    X = X.drop(columns='quantity_group')\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDXHD4wRJpBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "57cd08dc-1452-461c-8fde-162428234d17"
      },
      "source": [
        "# The status_group column is the target\n",
        "target = 'status_group'\n",
        "\n",
        "# Get a dataframe with all train columns except the target & id\n",
        "train_features = train.drop(columns=[target, 'id'])\n",
        "\n",
        "# Get a list of the numeric features\n",
        "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
        "\n",
        "# Get a series with the cardinality of the nonnumeric features\n",
        "cardinality = train_features.select_dtypes(exclude='number').nunique()\n",
        "\n",
        "# Get a list of all categorical features with cardinality <= 50\n",
        "categorical_features = cardinality[cardinality <= 500].index.tolist()\n",
        "\n",
        "# Combine the lists \n",
        "features = numeric_features + categorical_features\n",
        "print(len(features))\n",
        "print(features)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private', 'region_code', 'district_code', 'population', 'construction_year', 'date_recorded', 'basin', 'region', 'lga', 'public_meeting', 'recorded_by', 'scheme_management', 'permit', 'extraction_type', 'extraction_type_group', 'extraction_type_class', 'management', 'management_group', 'payment', 'payment_type', 'water_quality', 'quality_group', 'quantity', 'source', 'source_type', 'source_class', 'waterpoint_type', 'waterpoint_type_group']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RLZfwBuJ8en",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "e0d46237-682e-4203-b3f0-0b9177fa5af4"
      },
      "source": [
        "train_features.select_dtypes(exclude='number').nunique()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date_recorded              349\n",
              "funder                    1716\n",
              "installer                 1929\n",
              "wpt_name                 30661\n",
              "basin                        9\n",
              "subvillage               17231\n",
              "region                      21\n",
              "lga                        124\n",
              "ward                      2082\n",
              "public_meeting               2\n",
              "recorded_by                  1\n",
              "scheme_management           12\n",
              "scheme_name               2563\n",
              "permit                       2\n",
              "extraction_type             18\n",
              "extraction_type_group       13\n",
              "extraction_type_class        7\n",
              "management                  12\n",
              "management_group             5\n",
              "payment                      7\n",
              "payment_type                 7\n",
              "water_quality                8\n",
              "quality_group                6\n",
              "quantity                     5\n",
              "source                      10\n",
              "source_type                  7\n",
              "source_class                 3\n",
              "waterpoint_type              7\n",
              "waterpoint_type_group        6\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ha09aOuLG7s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "cc4bd5d7-8841-4c80-8a87-44a74eede178"
      },
      "source": [
        "print(numeric_features)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private', 'region_code', 'district_code', 'population', 'construction_year']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqzmhATUJ9c4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector \n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "X_test = test[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmxhBDf7KBuC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ba7a97fe-feb7-4bed-a3c3-e549d09a9765"
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(multi_class='auto', solver='lbfgs', n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Score on Train/Val\n",
        "print('Training Accuracy', pipeline.score(X_train, y_train))\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))\n",
        "\n",
        "# Predict on Test Data\n",
        "y_pred = pipeline.predict(X_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy 0.7335227272727273\n",
            "Validation Accuracy 0.7308080808080808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oexNrjqMKTC5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "20454159-e6d4-45bd-be38-4dff351723a7"
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(multi_class='auto', solver='lbfgs', n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Score on Train/Val\n",
        "print('Training Accuracy', pipeline.score(X_train, y_train))\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))\n",
        "\n",
        "# Predict on Test Data\n",
        "y_pred = pipeline.predict(X_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy 0.758543771043771\n",
            "Validation Accuracy 0.752104377104377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVQxDo31OSqz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3250d101-9941-481f-c5fe-2fce47a53dec"
      },
      "source": [
        "#using decision tree classifier\n",
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    DecisionTreeClassifier(min_samples_leaf=4, random_state=20)\n",
        ")\n",
        "\n",
        "# Fit on train\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Score on Train/Val\n",
        "print('Training Accuracy', pipeline.score(X_train, y_train))\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))\n",
        "\n",
        "# Predict on Test Data\n",
        "y_pred = pipeline.predict(X_test)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy 0.8876052188552188\n",
            "Validation Accuracy 0.7703703703703704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtpKNKZLbgPT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7703ad45-2b8b-4583-e10f-71ffa09bc949"
      },
      "source": [
        "#using decision tree classifier\n",
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    DecisionTreeClassifier(min_samples_leaf=6, random_state=10)\n",
        ")\n",
        "\n",
        "# Fit on train\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Score on Train/Val\n",
        "print('Training Accuracy', pipeline.score(X_train, y_train))\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))\n",
        "\n",
        "# Predict on Test Data\n",
        "y_pred = pipeline.predict(X_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy 0.8639520202020202\n",
            "Validation Accuracy 0.7742424242424243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkL3tLsVUqWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Kaggle Submission 1\n",
        "kaggle = sample_submission.copy()\n",
        "kaggle['status_group'] = y_pred\n",
        "kaggle.to_csv('oferbaharav_kaggle_submission1.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lChAdE7Qc9Of",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9e51bae7-2bf5-4ded-867c-b003102cac21"
      },
      "source": [
        "#using decision tree classifier\n",
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    DecisionTreeClassifier(min_samples_leaf=4, random_state=20)\n",
        ")\n",
        "\n",
        "# Fit on train\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Score on Train/Val\n",
        "print('Training Accuracy', pipeline.score(X_train, y_train))\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))\n",
        "\n",
        "# Predict on Test Data\n",
        "y_pred = pipeline.predict(X_test)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy 0.8883207070707071\n",
            "Validation Accuracy 0.767003367003367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LGdvPy2eeaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "03228626-9626-46bb-f613-63f241697e55"
      },
      "source": [
        "#using decision tree classifier\n",
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    DecisionTreeClassifier(min_samples_leaf=4, random_state=30)\n",
        ")\n",
        "\n",
        "# Fit on train\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Score on Train/Val\n",
        "print('Training Accuracy', pipeline.score(X_train, y_train))\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))\n",
        "\n",
        "# Predict on Test Data\n",
        "y_pred = pipeline.predict(X_test)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy 0.8875420875420875\n",
            "Validation Accuracy 0.7702861952861952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLLBNo5fe040",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Kaggle Submission 1\n",
        "kaggle = sample_submission.copy()\n",
        "kaggle['status_group'] = y_pred\n",
        "kaggle.to_csv('oferbaharav_kaggle_submission1.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}